name: MLOps Pipeline CI

on:
  push:
    branches: ["main"]
  pull_request:
    branches: ["main"]
  workflow_dispatch:
  schedule:
    - cron: "0 3 * * *"   # daily scheduled run (event-based + cron)

jobs:
  pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Generate CI sample data
        run: |
          python - <<'PY'
          import csv
          import gzip
          from pathlib import Path

          path = Path("tests/data/train_sample.gz")
          path.parent.mkdir(parents=True, exist_ok=True)
          header = [
              "id",
              "click",
              "site_id",
              "app_id",
              "site_domain",
              "app_domain",
              "device_type",
              "device_conn_type",
          ]

          rows = []
          for i in range(200):
              click = 1 if i % 10 == 0 else 0
              rows.append(
                  [
                      i,
                      click,
                      f"s{i % 5}",
                      f"a{i % 7}",
                      f"sd{i % 11}",
                      f"ad{i % 13}",
                      f"d{i % 3}",
                      f"dc{i % 2}",
                  ]
              )

          with gzip.open(path, "wt", newline="") as f:
              writer = csv.writer(f)
              writer.writerow(header)
              writer.writerows(rows)
          print(f"Wrote {path} with {len(rows)} rows")
          PY

      - name: Prepare runtime (mlflow + artifacts)
        run: |
          mkdir -p mlruns artifacts
          rm -f mlflow.db

      - name: Run Prefect training pipeline (CI small mode)
        env:
          # --- CI small mode (fast) ---
          CI: "true"
          AVAZU_TRAIN_GZ: "tests/data/train_sample.gz"

          CHUNK_SIZE: "50000"
          MAX_TRAIN_CHUNKS: "1"
          VAL_ROWS: "10000"
          VAL_CHUNKS: "1"

          # Keep model tiny for CI
          N_ESTIMATORS: "1"
          HASH_N_FEATURES: "262144"

          # Local MLflow tracking
          MLFLOW_TRACKING_URI: "sqlite:///mlflow.db"
        run: |
          python -u src/prefect_flow.py

      - name: Upload model artifact (.joblib)
        uses: actions/upload-artifact@v4
        with:
          name: ctr-model-joblib
          path: models/*.joblib

      - name: Upload metrics artifact (optional)
        uses: actions/upload-artifact@v4
        with:
          name: ctr-metrics
          path: metrics/*.json
